Kafka 0.9版本对Java client的api做出了较大调整，
本文主要总结了Kafka 0.9在集群搭建、高可用性、新API方面的相关过程和细节，
以及本人在安装调试过程中踩出的各种坑。

关于Kafka的结构、功能、特点、适用场景等，网上到处都是，我就不再赘述了，直接进入正文
Kafka 0.9集群安装配置
此处的坑：按照官方文档的说法，
	advertised.host.name和advertised.port这两个参数用于定义集群向Producer和 Consumer广播的节点host和port，
	如果不定义的话，会默认使用host.name和port的定义。
	但在实际应用中，我发现如果不定义 advertised.host.name参数，使用Java客户端从远端连接集群时，会发生连接超时，
	抛出异常：org.apache.kafka.common.errors.TimeoutException: Batch Expired
	经过debug发现，连接到集群是成功的，但连接到集群后更新回来的集群meta信息却是错误的：
	http://dl2.iteye.com/upload/attachment/0116/2134/643043e9-08d4-3402-9471-4c4adaaba323.png
	能够看到，metadata中的Cluster信息，节点的hostname是iZ25wuzqk91Z这样的一串数字，而不是实际的ip地址10.0.0.100和101。
	iZ25wuzqk91Z其实是远端主机的hostname，这说明在没有配置advertised.host.name 的情况下，
	Kafka并没有像官方文档宣称的那样改为广播我们配置的host.name，而是广播了主机配置的hostname。
	远端的客户端并没有配置 hosts，所以自然是连接不上这个hostname的。
	要解决这一问题，把host.name和advertised.host.name都配置成绝对 的ip地址就可以了。

接下来，我们在另一台主机也完成Kafka的安装和配置，然后在两台主机上分别启动Kafka：
	bin/kafka-server-start.sh -daemon config/server.properties
此处的坑：
	官方给出的后台启动kafka的方法是：bin/kafka-server-start.sh config/server.properties &
	但用这种方式启动后，只要断开Shell或登出，Kafka服务就会自动shutdown，
	不知是OS的问题还是SSH的问题还是Kafka自己的问题，总之我改用-daemon方式启动Kafka才不会在断开shell后自动shutdown。

接下来，我们创建一个名为test，拥有两个分区，两个副本的Topic：
	bin/kafka-topics.sh --create --zookeeper 10.0.0.100:2181,10.0.0.101:2181,10.0.0.102:2181 --replication-factor 2 --partitions 2 --topic tes

创建完成后，使用如下命令查看Topic状态：
	bin/kafka-topics.sh --describe --zookeeper 10.0.0.100:2181,10.0.0.101:2181,10.0.0.102:2181 --topic test
输出：
Topic:test PartitionCount:2 ReplicationFactor:2 Configs:
     Topic: test Partition: 0 Leader: 1 Replicas: 1,0 Isr: 0,1
     Topic: test Partition: 1 Leader: 0 Replicas: 0,1 Isr: 0,1
解读：test这个topic，当前有2个分区，分别为0和1，分区0的Leader是1（这个1是broker.id），分区0有两个 Replica（副本），
	分别是1和0，这两个副本中，Isr（In-sync）的是0和1。
	分区2的Leader是0，也有两个Replica，同样也 是两个replica都是in-sync状态

































