a1.sources = s
a1.channels = c
a1.sinks = r

producer.sources.s.type = spooldir
producer.sources.s.spoolDir = /home/hadoop/dir/logdfs
producer.sources.s.channels = c
producer.sources.s.fileHeader = false
producer.sources.s.interceptors = i1
producer.sources.s.interceptors.i1.type = timestamp

# http://flume.apache.org/FlumeUserGuide.html#kafka-sink
# https://github.com/beyondj2ee/flumeng-kafka-plugin/tree/master/flumeng-kafka-plugin
producer.sinks.r.type = org.apache.flume.plugins.kafkaSink
producer.sinks.r.metadata.broker.list=hadoop:9092
producer.sinks.r.partition.key=0
producer.sinks.r.partitioner.class=org.apache.flume.plugins.singlePartition
producer.sinks.r.serializer.class=kafka.serializer.StringEncoder
producer.sinks.r.request.required.acks=0
producer.sinks.r.max.message.size=1000000
producer.sinks.r.producer.type=sync
producer.sinks.r.custom.encoding=UTF-8
producer.sinks.r.custom.topic.name=kafka-ubas
producer.sinks.r.channel = c

producer.channels.ch1.type = file
producer.channels.channel1.checkpointDir = /opt/modules/flume-1.6.0/tmp/checkpointDir
producer.channels.channel1.dataDirs = /opt/modules/flume-1.6.0/tmp/dataDirs

