Kafka架构
Terminology
	Broker
		Kafka集群包含一个或多个服务器，这种服务器被称为broker
	Topic
		每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。
		（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上,
		但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）
	Partition
		Parition是物理上的概念，每个Topic包含一个或多个Partition.
	Producer
		负责发布消息到Kafka broker
	Consumer
		消息消费者，向Kafka broker读取消息的客户端。
	Consumer Group
		每个Consumer属于一个特定的Consumer Group
		（可为每个Consumer指定group name，若不指定group name则属于默认的group）。


Kafka拓扑结构
	http://www.jasongj.com/img/KafkaColumn1/KafkaArchitecture.png

	如上图所示，一个典型的Kafka集群中包含
	若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），
	若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），
	若干Consumer Group，以及一个Zookeeper集群。
	Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。
	Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。 　　

Topic & Partition
	Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic，可以简单理解为必须指明把这条消息放进哪个queue里。
	为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，
	每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。
		若创建topic1和topic2两个topic，且分别有13个和19个分区，则整个集群上会相应会生成共32个文件夹
		（本文所用集群共8个节点，此处topic1和topic2 replication-factor均为1），如下图所示。
		http://www.jasongj.com/img/KafkaColumn1/topic-partition.png

		每个日志文件都是一个log entrie序列，每个log entrie包含一个4字节整型数值（值为N+5），
		1个字节的”magic value”，4个字节的CRC校验码，其后跟N个字节的消息体。
		每条消息都有一个当前Partition下唯一的64字节的offset，它指明了这条消息的起始位置。
		磁盘上存储的消息格式如下：
			message length ： 4 bytes (value: 1+4+n)
			“magic” value ： 1 byte
			crc ： 4 bytes
			payload ： n bytes
		这个log entries并非由一个文件构成，而是分成多个segment，每个segment以该segment第一条消息的offset命名并以“.kafka”为后缀。
		另外会有一个索引文件，它标明了每个segment下包含的log entry的offset范围，如下图所示。
			http://www.jasongj.com/img/KafkaColumn1/partition_segment.png
		因为每条消息都被append到该Partition中，属于顺序写磁盘，因此效率非常高
		（经验证，顺序写磁盘效率比随机写内存还要高，这是Kafka高吞吐率的一个很重要的保证）。
			http://www.jasongj.com/img/KafkaColumn1/partition.png
		对于传统的message queue而言，一般会删除已经被消费的消息，而Kafka集群会保留所有的消息，无论其被消费与否。
		当然，因为磁盘限制，不可能永久保留所有数据（实际上也没必要），因此Kafka提供两种策略删除旧数据。
		一是基于时间，二是基于Partition文件大小。
			例如可以通过配置$KAFKA_HOME/config/server.properties，
			让Kafka删除一周前的数据，也可在Partition文件超过1GB时删除旧数据，配置如下所示。

			# The minimum age of a log file to be eligible for deletion
			log.retention.hours=168
			# The maximum size of a log segment file. When this size is reached a new log segment will be created.
			log.segment.bytes=1073741824
			# The interval at which log segments are checked to see if they can be deleted according to the retention policies
			log.retention.check.interval.ms=300000
			# If log.cleaner.enable=true is set the cleaner will be enabled and individual logs can then be marked for log compaction.
			log.cleaner.enable=false

	这里要注意，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，
	所以这里删除过期文件与提高Kafka性能无关。选择怎样的删除策略只与磁盘以及具体的需求有关。
	另外，Kafka会为每一个Consumer Group保留一些metadata信息——当前消费的消息的position，也即offset。
	这个offset由Consumer控制。正常情况下Consumer会在消费完一条消息后递增该offset。
	当然，Consumer也可将offset设成一个较小的值，重新消费一些消息。
	因为offet由Consumer控制，所以Kafka broker是无状态的，
	它不需要标记哪些消息被哪些消费过，也不需要通过broker去保证同一个Consumer Group只有一个Consumer能消费某一条消息，
	因此也就不需要锁机制，这也为Kafka的高吞吐率提供了有力保障。 　　

Producer消息路由
	Producer发送消息到broker时，会根据Paritition机制选择将其存储到哪一个Partition。
	如果Partition机制设置合理，所有消息可以均匀分布到不同的Partition里，这样就实现了负载均衡。
	如果一个Topic对应一个文件，那这个文件所在的机器I/O将会成为这个Topic的性能瓶颈，
	而有了Partition后，不同的消息可以并行写入不同broker的不同Partition里，极大的提高了吞吐率。
	可以在$KAFKA_HOME/config/server.properties中通过配置项num.partitions来指定新建Topic的默认Partition数量，
	也可在创建Topic时通过参数指定，同时也可以在Topic创建之后通过Kafka提供的工具修改。
　　
	在发送一条消息时，可以指定这条消息的key，Producer根据这个key和Partition机制来判断应该将这条消息发送到哪个Parition。
	Paritition机制可以通过指定Producer的paritition.class这一参数来指定，该class必须实现kafka.producer.Partitioner接口。
	本例中如果key可以被解析为整数则将对应的整数与Partition总数取余，该消息会被发送到该数对应的Partition。
	（每个Parition都会有个序号,序号从0开始）

		import kafka.producer.Partitioner;
		import kafka.utils.VerifiableProperties;

		public class JasonPartitioner<T> implements Partitioner {

			public JasonPartitioner(VerifiableProperties verifiableProperties) {}

			@Override
			public int partition(Object key, int numPartitions) {
				try {
					int partitionNum = Integer.parseInt((String) key);
					return Math.abs(Integer.parseInt((String) key) % numPartitions);
				} catch (Exception e) {
					return Math.abs(key.hashCode() % numPartitions);
				}
			}
		}

	如果将上例中的类作为partition.class，并通过如下代码发送20条消息（key分别为0，1，2，3）至topic3（包含4个Partition）。







